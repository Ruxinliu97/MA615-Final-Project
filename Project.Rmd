---
title: "Final Project"
author: "Ruxin Liu"
date: "12/13/2020"
output: pdf_document
---

# Introduction


  As we are now in a big data world, more and more data related jobs have been created
  recently among different fields. When we are searching these job positions online,
  it is very common to see diverse descriptions, titles and requirements among different
  companies and job boards. The main goal of this project is to explore some of 
  these varieties through the use of the application programming interface (API).


# Data Procesing 

  The data sources of this project are from Adzuna and The Muse, which are both online
  career platforms. After registering for the API ID and key, we could write queries
  to obtain the data and process the data in R and all the detailed codes for data
  cleaning and processing are in the file Data Processing.Rmd. 
  
  Adzuna is an employment website where its headquarters located in the United 
  Kingdom (Wikipedia 2020). From this site, we obtain 50-page of job information
  in Britain that has keywords of data, statisticians, statistician, analyst or 
  analysts. Also, we obtain 50-page of job information in America with the same
  list of key words. 

```{r, echo = FALSE}
# Read in the pre-processed data
muse_data <- read.csv("muse_data.csv")
Adzuna_data <- read.csv("Adzuna_data.csv")
Adzuna_us <- read.csv("Adzuna_us.csv")
```



# EDA (Exploratory Data Analysis)
### Adzuna Data -- UK


```{r, echo = FALSE, message=FALSE}
# Word Clouds
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
# Create a vector containing only the text
text_uk <- Adzuna_data$description
# Create a corpus  
docs_uk <- Corpus(VectorSource(text_uk))
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
# Clean the data -- remove some words, symbols & spaces
docs_uk <- docs_uk %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs_uk <- tm_map(docs_uk, content_transformer(tolower))
docs_uk <- tm_map(docs_uk, removeWords, stopwords("english"))
```

```{r, echo = FALSE}
# Create a document-term-matrix
dtm_uk <- TermDocumentMatrix(docs_uk) 
matrix_uk <- as.matrix(dtm_uk) 
words_uk <- sort(rowSums(matrix_uk),decreasing=TRUE) 
df_uk <- data.frame(word = names(words_uk),freq=words_uk)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
# For reproducibility 
set.seed(1997) 
wordcloud(words = df_uk$word, freq = df_uk$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```

```{r,echo = FALSE, message=FALSE, warning=FALSE}
# Add the indicator to determine whether the title contains "Statistician"
Adzuna_data$Statistician <- ifelse(grepl("Statistician",Adzuna_data$title) == "TRUE", 1, 0)
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
ggplot(Adzuna_data) +
  geom_boxplot(aes(x = factor(Statistician), y = salary_max, fill=factor(Statistician))) +
  ylab("Maximum Salary") +
  xlab("Statistician Indicator") +
  ggtitle("Fig. : Maximum Salary Distributions for Statistician and Non-statistician") +
  scale_fill_discrete(name = "Statistician Indicator", labels = c("Job Title Not Containing Statistician", "Job Title Containing Statistician"))
```


### Adzuna Data -- US

```{r, echo = FALSE, message=FALSE, warning=FALSE}
text_us <- Adzuna_us$description
docs_us <- Corpus(VectorSource(text_us))

docs_us <- docs_us %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs_us <- tm_map(docs_us, content_transformer(tolower))
docs_us <- tm_map(docs_us, removeWords, stopwords("english"))

dtm_us <- TermDocumentMatrix(docs_us) 
matrix_us <- as.matrix(dtm_us) 
words_us <- sort(rowSums(matrix_us),decreasing=TRUE) 
df_us <- data.frame(word = names(words_us),freq=words_us)

set.seed(1997) 
wordcloud(words = df_us$word, freq = df_us$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```







### The Muse
```{r, echo = FALSE, message = FALSE}
library(dplyr)
# Whether SQL is mentioned in the job description
muse_data$sql <- grepl("SQL",muse_data$contents)
# Whether Python is mentioned in the job description
muse_data$Python <- grepl("Python",muse_data$contents)
muse_data$analysis <- grepl("analysis",muse_data$contents)
```

```{r, echo = FALSE}
level_num <- muse_data %>% 
  group_by(level) %>% 
  tally()
kableExtra::kable(level_num)
```

```{r, message=FALSE, echo = FALSE}
library(tidyverse)
ggplot(muse_data, aes(level, fill = sql)) +
  geom_bar()
```

```{r, message=FALSE, echo = FALSE}
ggplot(muse_data, aes(level, fill = Python)) +
  geom_bar()
```

```{r, message=FALSE, echo = FALSE}
ggplot(muse_data, aes(level, fill = analysis)) +
  geom_bar()
```

```{r, echo = FALSE, message=FALSE}
text <- muse_data$contents
docs <- Corpus(VectorSource(text))

docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))

dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)

set.seed(1997) 
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```

# Discussion 

# Limitations & Future Direction 

* Since for some job sites, there are daily limitations in utilization when using
API to query the data, it takes long time to get the data. Also, since the job 
sites have new updates every day, it is almost impossible to have the complete/full
data. Therefore, it could been developed into a more long-term project in the future,
which can have some updates on a regular base. 

*

# Bibliography

1. Jeroen Ooms (2014). The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R
  Objects. arXiv:1403.2805 [stat.CO] URL https://arxiv.org/abs/1403.2805.
  
2. Hadley Wickham (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version
  1.4.0. https://CRAN.R-project.org/package=stringr
  
3. Wikipedia (2020). *Adzuna* [online]. Available from: https://en.wikipedia.org/wiki/Adzuna [accessed 13 December 2020].

4. Wikipedia (2020). *The Muse* [online]. Available from: https://en.wikipedia.org/wiki/The_Muse_(website) [accessed 13 December 2020].

5. Hao Zhu (2019). kableExtra: Construct Complex Table with 'kable' and Pipe Syntax. R package version 1.1.0.
  https://CRAN.R-project.org/package=kableExtra
  
6. Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686
  
7.  Ian Fellows (2018). wordcloud: Word Clouds. R package version 2.6.
  https://CRAN.R-project.org/package=wordcloud

8. Erich Neuwirth (2014). RColorBrewer: ColorBrewer Palettes. R package version 1.1-2.
  https://CRAN.R-project.org/package=RColorBrewer
  
9. Ingo Feinerer and Kurt Hornik (2020). tm: Text Mining Package. R package version 0.7-8.
  https://CRAN.R-project.org/package=tm
  
10. Towards Data Science (2019). *How to Generate Word Clouds in R* [online]. Available from: https://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a [accessed 13 December 2020].

