---
title: "MA615 Final Project"
author: "Ruxin Liu"
date: "12/12/2020"
output: pdf_document
---

# Introduction


  As we are now in a big data world, more and more data related jobs have been created
  recently among different fields. When we are searching these job positions online,
  it is very common to see diverse descriptions, titles and requirements among different
  companies and job boards. The main goal of this project is to explore some of 
  these varieties through the use of the application programming interface (API).


# Data Procesing 

  The data source of this project is from Adzuna and The Muse, which are both online
  career platforms. After registering for the API ID and key, we could write queries
  to obtain the data and process the data in R. Adzuna is an employment website 
  where its headquarters located in the United Kingdom (Wikipedia 2020). From this
  site, we obtain some job information in Britain that has keywords of data, statisticians,
  statistician, analyst or analysts. 

```{r, echo = FALSE, eval = FALSE}
library(jsonlite)
Adzuna_file <- jsonlite::fromJSON("https://api.adzuna.com/v1/api/jobs/gb/search/1?app_id=953c7802&app_key=7c8ece93f1f774f74085f3a09c61a3ae&results_per_page=50&what_or=data%20statisticians%20statistician%20analyst%20analysts", flatten = TRUE)
Adzuna_data <- Adzuna_file$results
```

```{r, echo = FALSE, eval = FALSE}
# The 1st part of the url
url_1 <- "https://api.adzuna.com/v1/api/jobs/gb/search/"
# The 2nd part of the url, set per_page = 50 to read the maximum results per time
url_2 <- "?app_id=953c7802&app_key=7c8ece93f1f774f74085f3a09c61a3ae&results_per_page=50&what_or=data%20statisticians%20statistician%20analyst%20analysts"

library(stringr)

for(i in 2 : 50) {
  url_Adzuna <- str_c(url_1, i, url_2, sep = "")
  Adzuna_file <- jsonlite::fromJSON(url_Adzuna, flatten=TRUE)
  Adzuna <- Adzuna_file$results
  Adzuna_data <- bind_rows(Adzuna_data, Adzuna)
}
```



```{r, echo = FALSE, eval = FALSE}
themuse_file <- jsonlite::fromJSON("https://www.themuse.com/api/public/jobs?company=Amazon&company=Facebook&company=TripAdvisor&category=Data%20Science&api_key=05db5552751b2cbc084c19c517084ae6b3c7a69b2af3e7d07968fdc02f53ff39&page=3", flatten=TRUE)
View(themuse_file$results)
```


```{r, echo = FALSE, eval = FALSE}
muse_file <- jsonlite::fromJSON("https://www.themuse.com/api/public/jobs?company=Amazon&company=Facebook&category=Data%20Science&api_key=05db5552751b2cbc084c19c517084ae6b3c7a69b2af3e7d07968fdc02f53ff39&page=1", flatten=TRUE)
muse_data <- muse_file$results
```



```{r, echo = FALSE, eval = FALSE}
# The 1st part of the url
url_1 <- "https://www.themuse.com/api/public/jobs?company=Amazon&company=Facebook&category=Data%20Science&api_key=05db5552751b2cbc084c19c517084ae6b3c7a69b2af3e7d07968fdc02f53ff39&page="
library(stringr)
library(dplyr)
for(i in 2 : 500) {
  url <- str_c(url_1, i, sep = "")
  themuse_file <- jsonlite::fromJSON(url, flatten=TRUE)
  themuse <- themuse_file$results
  muse_data <- bind_rows(muse_data, themuse)
}
```

```{r, echo = FALSE, eval = FALSE}
for(i in 64 : 500) {
  url <- str_c(url_1, i, sep = "")
  themuse_file <- jsonlite::fromJSON(url, flatten=TRUE)
  themuse <- themuse_file$results
  muse_data <- bind_rows(muse_data, themuse)
}
```

```{r, echo = FALSE, eval = FALSE}
muse_data$locations <- unlist(unname(muse_data[[8]]))
```

```{r, echo = FALSE, eval = FALSE}
level <- numeric(0)
for(i in 1 : 1239) {
  level <- c(level, unlist(muse_data[[10]][[i]]$short_name))
}
```

```{r, echo = FALSE, eval = FALSE}
muse_data$level <- level

muse_data <- muse_data[, -c(9, 10, 11)]
```

```{r, echo = FALSE}
# Read in the pre-processed data
muse_data <- read.csv("muse_data.csv")
Adzuna_data <- read.csv("Adzuna_data.csv")
```




# EDA (Exploratory Data Analysis)

```{r, echo = FALSE}
library(dplyr)
# Whether SQL is mentioned in the job description
muse_data$sql <- grepl("SQL",muse_data$contents)
# Whether Python is mentioned in the job description
muse_data$Python <- grepl("Python",muse_data$contents)
```

```{r, echo = FALSE}
level_num <- muse_data %>% 
  group_by(level) %>% 
  tally()
kableExtra::kable(level_num)
```

```{r, message=FALSE, echo = FALSE}
library(tidyverse)
ggplot(muse_data, aes(level, fill = sql)) +
  geom_bar()
```

```{r, message=FALSE, echo = FALSE}
ggplot(muse_data, aes(level, fill = Python)) +
  geom_bar()
```

```{r, echo = FALSE}
# Word Clouds
library(wordcloud)
library(RColorBrewer)
library(wordcloud2)
library(tm)
# Create a vector containing only the text
text <- muse_data$contents
# Create a corpus  
docs <- Corpus(VectorSource(text))
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
# Clean the data -- remove some words or symbols 
docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
gsub("<strong>", "", muse_data$contents) 
gsub("<br>", "", muse_data$contents) 
```

```{r, echo = FALSE}
# Create a document-term-matrix
dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)
```

```{r, warning=FALSE, message=FALSE, echo = FALSE}
# For reproducibility 
set.seed(1997) 
wordcloud(words = df$word, freq = df$freq, min.freq = 1, max.words=200, random.order=FALSE, rot.per=0.35,            colors=brewer.pal(8, "Dark2"))
```


# Limitations & Future Direction 

* Since for some job sites, there are daily limitations in utilization when using
API to query the data, it takes long time to get the data. Also, since the job 
sites have new updates every day, it is almost impossible to have the complete/full
data. Therefore, it could been developed into a more long-term project in the future,
which can have some updates on a regular base. 

*

# Bibliography

1. Jeroen Ooms (2014). The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R
  Objects. arXiv:1403.2805 [stat.CO] URL https://arxiv.org/abs/1403.2805.
  
2. Hadley Wickham (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version
  1.4.0. https://CRAN.R-project.org/package=stringr
  
3. Wikipedia (2020). *Adzuna* [online]. Available from: https://en.wikipedia.org/wiki/Adzuna [accessed 13 December 2020].

4. Wikipedia (2020). *The Muse* [online]. Available from: https://en.wikipedia.org/wiki/The_Muse_(website) [accessed 13 December 2020].

5. Hao Zhu (2019). kableExtra: Construct Complex Table with 'kable' and Pipe Syntax. R package version 1.1.0.
  https://CRAN.R-project.org/package=kableExtra
  
6. Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686
  
7.  Ian Fellows (2018). wordcloud: Word Clouds. R package version 2.6.
  https://CRAN.R-project.org/package=wordcloud

8. Erich Neuwirth (2014). RColorBrewer: ColorBrewer Palettes. R package version 1.1-2.
  https://CRAN.R-project.org/package=RColorBrewer
  
9. Ingo Feinerer and Kurt Hornik (2020). tm: Text Mining Package. R package version 0.7-8.
  https://CRAN.R-project.org/package=tm
  
10. 